\chapter{Μέθοδοι Εσωτερικού Σημείου}\label{ch:ip}
\section{Ιστορικά στοιχεία}
Ο γραμμικός προγραμματισμός σύμφωνα με το βιβλίο \cite{wright1997primal}
είναι ένας από τους πιο πετυχημένους τομείς της
βελτιστοποίησης. Από τη διατύπωσή του τη δεκαετία του \(1930\) μέχρι την
ανάπτυξη του αλγορίθμου \tl{simplex} τη δεκαετία του \(1940\) από τον
\tl{Dantzig}, γενιές εργαζομένων στα οικονομικά, στη μηχανική και άλλους τομείς
εκπαιδεύτηκαν για να λύνουν προβλήματα γραμμικού προγραμματισμού. Ακόμα και όταν
τα μοντέλα ήταν μη-γραμμικά, γραμμικές μέθοδοι χρησιμοποιούνταν λόγω της μεγάλης
ανάπτυξης που είχαν.

Η δημοσίευση το \(1948\) του \tl{Karmarkar} \cite{karmarkar1984} ήταν το πιο σημαντικό γεγονός στο
γραμμικό προγραμματισμό μετά την ανακάλυψη της μεθόδου \tl{simplex}. Ο λόγος
ήταν ότι ο αλγόριθμος του \tl{Karmarkar} υποσχόταν πολυωνυμική πολυπλοκότητα, σε
σύγκριση με τη λογαριθμική πολυπλοκότητα της μεθόδου \tl{simplex}, και
εξαιρετική πρακτική επίδοση σε μεγάλου μεγέθους προβλήματα. Οι ισχυρισμοί αυτοί
δεν επιβεβαιώθηκαν, αλλά η δημοσίευση έδωσε μία επανάσταση στην έρευνα του
γραμμικού προγραμματισμού που οδήγησε σε έναν νέο τομέα αλγορίθμων που
ονομάζονται μέθοδοι εσωτερικού σημείου. Στις παρακάτω ενότητες θα περιγράψουμε
κάποιους τυπικούς αλγορίθμους εσωτερικών σημείων. Θα ξεκινήσουμε με τη μέθοδο
\tl{affine scaling} που αποτελεί μία εισαγωγή για τον αλγόριθμο του
\tl{Karmarkar}, τη βάση τις οικογένειας αλγορίθμων εσωτερικού σημείου. Στη
συνέχεια θα παρουσιάσουμε τους αλγορίθμους \tl{path-following} (ή μέθοδος
φράγματος) και \tl{primal-dual} που κυρίως χρησιμοποιούνται σε πρακτικές
εφαρμογές στις μέρες μας.

\section{Μέθοδος \tl{affine scaling}}
Σε αυτή την ενότητα θα περιγράψουμε έναν απλό αλγόριθμο, που ονομάζεται
\tl{affine scaling}, για την επίλυση προβλημάτων γραμμικών προγραμματισμού,
βασιζόμενοι στο βιβλίο \cite{chong2010}. Η μέθοδος αυτή είναι μία μέθοδος
εσωτερικού σημείου και επιτελεί το ρόλο εισαγωγής στον αλγόριθμο του
\tl{Karmarkar}. Γενικά, οι μέθοδοι εσωτερικού σημείου διαφέρουν από τη μέθοδο
\tl{simplex} σε ένα βασικό σημείο: η μέθοδος εσωτερικού σημείου ξεκινάει στο
εσωτερικού του εφικτού συνόλου και κινείται σε αυτό για την εύρεση βέλτιστου
σημείου. Αντίθετα, η μέθοδος \tl{simplex} κινείται στις κορυφές του εφικτού
συνόλου.

Έστω το γραμμικό πρόβλημα
\begin{equation*}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & c^T x \\
        & \text{\tl{subject to}}
        & & A x = b \\
        &&& x \ge 0.
    \end{aligned}
\end{equation*}
Έστω ότι έχουμε το εφικτό σημείο \( x^{(0)} \) που είναι αυστηρώς εσωτερικό
(δηλαδή \( x > 0\)). Θέλουμε να βρούμε ένα νέο σημείο \( x^{(1)} \) ψάχνοντας
στη διεύθυνση του \( d^{(0)} \) που μειώνει την αντικειμενική συνάρτηση. Δηλαδή
\begin{equation*}
    x^{(1)} = x^{(0)} + a_0 d^{(0)},
\end{equation*}
με \(a_0\) το μέγεθος του βήματος. Προκειμένου το \( x^{(1)} \) να βρίσκεται
εντός του εφικτού συνόλου, είναι απαραίτητο το διάνυσμα \( d^{(0)} \) να
βρίσκεται στο μηδενοχώρο του \(A\), με άλλα λόγια θέλουμε να ισχύει
\( Ax^{(1)} = b\). Επειδή, το \( x^{(0)} \) είναι εφικτό σημείο από τις παραπάνω
εξισώσεις προκύπτει
\begin{equation*}
    A\left( x^{(1)} - x^{(0)} \right) = a_0Ad^{(0)} = 0.
\end{equation*}
Για να επιλέξουμε \( d^{(0)} \) που να βρίσκεται στο μηδενοχώρο του \(A \) και
να κινείται στην μείωση της αντικειμενικής, δηλαδή κοντά στο \(-c\), παίρνουμε την
ορθογώνια προβολή του \(-c\) στο μηδενοχώρο του \(A\). Αυτή η προβολή
περιγράφεται από τον πίνακα
\begin{equation*}
    P = I_n - A^T(AA^T){-1}A.
\end{equation*}
Έτσι θέτουμε το \( d^{(0)} \) να είναι στη διεύθυνση της ορθογώνιας προβολής του
\( -c \) στο μηδενοχώρο του \(A\)
\begin{equation*}
    d^{(0)} = - Pc,
\end{equation*}
και έτσι, βρίσκουμε ένα καινούργιο εφικτό σημείο \( x^{(1)} \) από τη σχέση
\begin{equation*}
    x^{(1)} = x^{(0)} - a_0Pc.
\end{equation*}

Παρατηρώντας τις σχέσεις καταλήγουμε στο συμπέρασμα ότι αν το αρχικό εφικτό
σημείο βρίσκεται στο \tl{``}κέντρο\tl{''} του εφικτού συνόλου, τότε μπορούμε να
κινηθούμε με μεγαλύτερο βήμα και αυτό σημαίνει μεγαλύτερη μείωση στην τιμή της
αντικειμενικής και άρα ταχύτερη σύγκλιση.

Στην περίπτωση που το αρχικό σημείο δεν βρίσκεται στο κέντρο του συνόλου,
μπορούμε με έναν αφηνικό μετασχηματισμό να το μετατρέψουμε σε κεντρικό. Για να
μετατρέψουμε το \( x^{(0)} \) στο κεντρικό σημείο \(e\), χρησιμοποιούμε τον
αφηνικό μετασχηματισμό (\tl{affine scaling transformation})
\begin{equation*}
    e = D_0^{-1}x^{(0)},
\end{equation*}
όπου \( D_0 = \text{\tl{diag}}\left[ x_1^{(0)}, \dots, x_n^{(n)} \right]\). Με την
υπόθεση που κάναμε ότι το \( x^{(0)} \) είναι αυστηρώς εσωτερικό, ο πίνακας
\(D_0 \) είναι αντιστρέψιμος. Προφανώς, στην πράξη δεν επιδιώκουμε να βρούμε το
κεντρικό σημείο αλλά κάποιο σημείο αρκετά κοντά σε αυτό με μικρή σχετικά
απόκλιση. Βασικό βέβαια είναι το αρχικό σημείο να είναι αυστηρώς εσωτερικό.

Με την παραπάνω διαδικασία, μετατρέψαμε το αρχικό εφικτό διάνυσμα
\( x^{(0)} \) με το μετασχηματισμό \( D_0^{-1} \) και ουσιαστικό αλλάξαμε βάση.
Έτσι στη νέα βάση το πρόβλημα της ενότητας μετασχηματίζεται στο
αντίστοιχο γραμμικό
\begin{equation*}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & \bar{c}_0^T \bar{x} \\
        & \text{\tl{subject to}}
        & & \bar{A}_0 \bar{x} = b \\
        &&& \bar{x} \ge 0,
    \end{aligned}
\end{equation*}
όπου
\begin{equation*}
    \bar{c}_0 = D_0c, \quad \bar{A}_0 = AD_0.
\end{equation*}
Εφαρμόζοντας τη διαδικασία που περιγράψαμε παραπάνω στο νέο σύστημα
συντεταγμένων, υπολογίζουμε την επόμενη τιμή από τη σχέση
\begin{equation*}
    \bar{x}^{(1)} = \bar{x}^{(0)} - a_0\bar{P}_0\bar{c}_0,
\end{equation*}
με \( \bar{x}^{(0)} = D_0^{-1}x^{(0)} \). Το νέο σημείο στις αρχικές
συντεταγμένες δίνεται με το μετασχηματισμό \( x^{(1)} = D_0 \bar{x}^{(1)} \).
Επαναλαμβάνοντας τη διαδικασία για μία ακολουθία σημείων \( \{ x^{(k)} \} \), όπου
\begin{equation*}
    x^{(k+1)} = x^{(k)} + a_kd^{(k)},
\end{equation*}
με
\begin{align*}
    D_k &= \text{\tl{diag}}\left[ x^{(k)}_1, \dots, x_n^{(k)} \right] \\
    \bar{A}_k &= AD_k \\
    \bar{P}_k &= I_n - \bar{A}^T_k \left(\bar{A}_k\bar{A}_k^T
    \right)^{-1}\bar{A}_k \\
    d^{(k)} &= -D_k\bar{P}_kD_kc.
\end{align*}
Σε κάθε βήμα του αλγορίθμου πρέπει να εξασφαλίζουμε ότι το \( x^{(k)} \) είναι
αυστηρώς εσωτερικό. Η συνθήκη των περιορισμών ικανοποιείται λόγω του τρόπου που
επιλέξαμε το \( d^{(k)} \). Όμως, πρέπει ακόμα να εξασφαλίσουμε ότι
\(x_i^{(k)} > 0 \) για \( i = 1, \dots, n \), και αυτό γίνεται με την κατάλληλη
επιλογή του βήματος, \(a_k\).

Αναφέραμε ήδη ότι επιδιώκουμε μεγάλο βήμα, για αυτό το λόγο πραγματοποιούμε τον
αφινικό μετασχηματισμό στο αρχικό σημείο για να το μετατρέψουμε σε κεντρικό.
Όμως πρέπει να επιλέξουμε τέτοιο βήμα ούτως ώστε το νέο σημείο να είναι θετικό.
Για να το επιτύχουμε αυτό, ορίζουμε
\begin{equation*}
    r_k = \underset{\{i: d_i^{(k)} < 0\}} {\text{\tl{min}}}
    -\frac{x^{(k)}_i}{d^{(k)}_i},
\end{equation*}
που αντιπροσωπεύει το μεγαλύτερο βήμα \( a_k \) έτσι ώστε οι συνιστώσες του
\( x^{(k+1)} \) να είναι μη-αρνητικές και υπολογίζουμε το βήμα από τη σχέση
\( a_k = \alpha r_k \) με \( \alpha \in (0, 1) \). Τυπικές τιμές του συντελεστή
\( \alpha \) είναι \(0.9\) ή \(0.99\).

Σε αντίθεση με άλλες μεθόδους, η μέθοδος \tl{affine scaling} μέθοδος δε θα
φτάσει σε βέλτιστη λύση σε πεπερασμένο αριθμό βημάτων στη γενική περίπτωση.
Επομένως, είναι απαραίτητο κάποιο κριτήριο τερματισμού και συχνά στη
βιβλιογραφία συναντάται η σχέση
\begin{equation*}
    \frac{ | cx^{(k+1)} - cx^{(k)} |} {\max{1, |cx^{(k)}|}} < \epsilon,
\end{equation*}
με το \( \epsilon \) να έχει επιλεχθεί ανάλογα με την ακρίβεια που επιθυμούμε.
Πολλές φορές στην πράξη δε γνωρίζουμε το αρχικό εφικτό σημείο. Ακόμα η εύρεση
του σημείου αυτού δεν είναι προφανής. Για το λόγο αυτό έχουν αναπτυχθεί κάποιες
μεθοδολογίες για τον υπολογισμό αυτού και την έναρξη της μεθόδου. Ο
ενδιαφερόμενος αναγνώστης παραπέμπεται στο βιβλίο \cite{chong2010} για τη
διαδικασία εύρεσης αρχικής εφικτής λύσης.

\section{Ο αλγόριθμος του \tl{Karmarkar}}
Ο αλγόριθμος του \tl{Karmarkar} ήταν ο πρώτος αλγόριθμος εσωτερικού σημείου που
εμφανίστηκε. Παρόλο που σήμερα δεν χρησιμοποιείται, τουλάχιστον όχι στη μορφή
που παρουσιάστηκε από τον \tl{Karmarkar}, καθώς οι αλγόριθμοι
εσωτερικού σημείου του παρόντος κεφαλαίου παρουσιάζουν
καλύτερες ιδιότητες, αξίζει να αναφερθούμε στη μέθοδο αυτή. Η προσέγγιση
που θα ακολουθήσει βασίστηκε στο βιβλίο \cite{chong2010} και αφορά γραμμικά
προβλήματα. Για τροποποιήσεις της μεθόδου για μη-γραμμικά προβλήματα προτείνεται
το βιβλίο \cite{nesterov1994interior}.

\subsection{Κανονική μορφή του \tl{Karmarkar}}
Για να εφαρμοστεί ο αλγόριθμος του \tl{Karmarkar} πρέπει το γραμμικό πρόβλημα να
μετασχηματιστεί σε συγκεκριμένη μορφή, η λεγόμενη κανονική μορφή του
\tl{Karmarkar} της μορφής
\begin{equation*}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & c^T x \\
        & \text{\tl{subject to}}
        & & A x = 0 \\
        &&& \sum_{i=1}^n x_i = 1 \\
        &&& x \ge 0,
    \end{aligned}
\end{equation*}
όπου \( x = [x_1, \dots, x_n]^T \). Για τη συνέχεια, χωρίς μείωση της
γενικότητας θα θεωρήσουμε ότι \( A, c\) είναι ακέραιοι.

Αρχικά, θα δώσουμε κάποιους συμβολισμούς, Έστω \( e = [1, \dots, 1]^T \) το
μοναδιαίο διάνυσμα στο \( \mathbb{R}^n \). Έστω \( \Omega \) ο μηδενοχώρος του
\(A\), δηλαδή το σύνολο
\begin{equation*}
    \Omega = \{ x \in \mathbb{R}^n: Ax = 0\}.
\end{equation*}
Ορίζουμε το \tl{simplex} ως
\begin{equation*}
    \Delta = \{ x \in \mathbb{R}^n: e^Tx = 1, x \geq 0\},
\end{equation*}
και δηλώνουμε το κέντρο του \tl{simplex} \(\Delta \) με
\begin{equation*}
    a_0 = \frac{e}{n} = \begin{bmatrix}
        \frac{1}{n}, \dots, \frac{1}{n}
    \end{bmatrix}^T.
\end{equation*}
Έτσι η κανονική μορφή του \tl{Karmarkar} μπορεί να γραφτεί ως
\begin{equation}\label{eq:ip_kar_can}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & c^T x \\
        & \text{\tl{subject to}}
        & & x \in \Omega \cap \Delta,
    \end{aligned}
\end{equation}
με το σύνολο των περιορισμών, δηλαδή το εφικτό σύνολο να είναι
\begin{equation*}
    \Omega \cap \Delta = \{ x \in \mathbb{R}^n: Ax = 0, e^Tx = 1, x \geq 0 \}.
\end{equation*}

\subsection{Το πρόβλημα του \tl{Karmarkar} υπό περιορισμούς}
Ο αλγόριθμος του \tl{Karmarkar} λύνει γραμμικά προβλήματα που είναι στην
κανονική μορφή που περιγράψαμε με τις ακόλουθες υποθέσεις:
\begin{enumerate}
    \item Το κέντρο \(a_0\) του \tl{simplex} \(\Delta\) είναι εφικτό σημείο,
        δηλαδή \(a_0 \in \Omega\).
    \item Η ελάχιστη τιμή της αντικειμενικής συνάρτησης στο εφικτό σύνολο είναι
        μηδέν.
    \item O \( (m + 1) \times n \) πίνακας
        \begin{equation*}
            \begin{pmatrix} A \\ e^T \end{pmatrix}
        \end{equation*}
        έχει βαθμό \( m + 1 \).
    \item Μας δίνεται παράμετρος τερματισμού \( q > 0 \), τέτοια ώστε αν βρούμε
        εφικτό σημείο που να ικανοποιεί
        \begin{equation*}
            \frac{c^Tx}{c^Ta_0} \leq 2^{-q},
        \end{equation*}
        τότε θεωρούμε ότι το πρόβλημα λύθηκε.
\end{enumerate}
Κάθε γραμμικό πρόβλημα που είναι της κανονικής μορφής του \tl{Karmarkar} και
ικανοποιεί τις τέσσερις παραπάνω υποθέσεις καλείται πρόβλημα \tl{Karmarkar} υπό
περιορισμούς. Συγκεκριμένα, η πρώτη υπόθεση δεν είναι περιοριστική, διότι
οποιοδήποτε γραμμικό πρόβλημα που έχει βέλτιστη λύση μπορεί να μετασχηματιστεί
σε κανονική μορφή που ικανοποιεί την υπόθεση αυτήν. Όσον αφορά την δεύτερη
υπόθεση, κάθε κανονικοποιημένο γραμμικό πρόβλημα μπορεί να μετατραπεί ούτως ώστε
να ικανοποιείται η δεύτερη υπόθεση με την προϋπόθεση ότι γνωρίζουμε εκ των
προτέρων την ελάχιστη τιμή της αντικειμενικής. Η τρίτη υπόθεση σχετίζεται με την
εφαρμογή του αλγορίθμου και η τέταρτη έχει να κάνει με τη συνθήκη τερματισμού
που είναι χαρακτηριστικό των αριθμητικών μεθόδων.

\subsection{Μετασχηματισμός στην κανονική μορφή του \tl{Karmarkar}}
Θα δείξουμε πως κάθε γραμμικό πρόβλημα μπορεί να μετασχηματιστεί σε ισοδύναμο
πρόβλημα της κανονικής μορφής του \tl{Karmarkar}, δηλαδή σε η λύση του
ενός μπορεί να χρησιμοποιηθεί για να βρούμε λύση για το άλλο. Ένα τυπικό
γραμμικό πρόβλημα είναι της μορφής
\begin{equation*}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & c^T x \\
        & \text{\tl{subject to}}
        & & Ax = b \\
        &&& x \geq 0,
    \end{aligned}
\end{equation*}
με \( x \in \mathbb{R}^n\). Μία απλή μέθοδος για να μετασχηματίσουμε το παραπάνω
είναι ορίζοντας μία νέα μεταβλητή \( z \in \mathbb{R}^{n+1} \) ως
\begin{equation*}
    z = \begin{pmatrix}x \\ 1 \end{pmatrix}.
\end{equation*}
Ακόμη, ορίζουμε \( c' = (c^T, 0)^T \) και \( A' = (A, -b) \). Με τους
συμβολισμούς αυτούς προκύπτει
\begin{equation*}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & c'^T x \\
        & \text{\tl{subject to}}
        & & A'z = 0 \\
        &&& z \geq 0.
    \end{aligned}
\end{equation*}
Ένα ακόμα βήμα χρειάζεται για να μετατρέψουμε το πρόβλημα σε αντίστοιχο με τους
περιορισμούς να αθροίζονται την μονάδα. Ορίζουμε \( y = (y_1, \dots, y_{n+1})^T
\in \mathbb{R}^{n+1} \) όπου
\begin{align*}
    y_i &= \frac{x_i}{x_1 + \dots + x_n + 1}, \quad i = 1, \dots, n \\
    y_{n+1} &= \frac{1}{x_1 + \dots + x_n + 1}.
\end{align*}
Ο μετασχηματισμός αυτός από τις μεταβλητές \(x\) στις \(y\) λέγεται προβολικός
μετασχηματισμός. Με τον τρόπο αυτόν μετατρέψαμε το αρχικό γραμμικό πρόβλημα στο
αντίστοιχο της κανονικής μορφής \tl{Karmarkar}
\begin{equation*}
    \begin{aligned}
        & {\text{\tl{minimize}}}
        & & c'^T y \\
        & \text{\tl{subject to}}
        & & A'y = 0 \\
        &&& e^Ty = 1 \\
        &&& y \geq 0.
    \end{aligned}
\end{equation*}
Η τεχνική αυτή μπορεί να αλλαχθεί ελαφρώς για να εξασφαλίσουμε ότι η πρώτη
υπόθεση του προηγούμενου υπο-κεφαλαίου θα ικανοποιείται. Περισσότερες
λεπτομέρειες μπορούν να βρεθούν στο βιβλίο του \cite{chong2010}.

\subsection{Διατύπωση του αλγορίθμου του \tl{Karmarkar}}
Στο σημείο αυτό μπορούμε να περιγράψουμε τον αλγόριθμο του \tl{Karmarkar}. Ο
αλγόριθμος αφορά γραμμικό πρόβλημα που είναι της κανονικής μορφής του
\tl{Karmarkar} και  ικανοποιούνται οι τέσσερις υποθέσεις που περιγράφηκαν
προηγουμένως, έχουμε δηλαδή να κάνουμε με το πρόβλημα της σχέσης
\eqref{eq:ip_kar_can}. Ο αλγόριθμος είναι επαναληπτικός και ξεκινάει δοθέντος
ενός αρχικού σημείου \(x^{(0)}\) και της παραμέτρου \( q\) και δίνει μία
ακολουθία σημείων \( x^{(1)}, x^{(2)}, \dots, x^{(N)} \).
\begin{figure}[h]
    \begin{otherlanguage}{english}
        \begin{algorithmic}
            \REQUIRE \text{\gr{1. \textbf{Όρισε}: }}
            \(k := 0, x^{(0)} = a_0 = e/n\)
            \REPEAT
            \STATE \text{\gr{2. \textbf{Ανανέωσε}: Θέσε }}
            \(x^{(k+1)} := \Psi(x^{(k)})\)
            \text{\gr{ όπου \(\Psi\) είναι ο πίνακας ανανέωσης}}
            \STATE \text{\gr{3. \textbf{Επανέλαβε}: Θέσε }}
            \(k := k + 1\)
            \UNTIL{
                \text{\gr{4. \textbf{Κριτήριο τερματισμού}: Να ικανοποιείται }}
                \(c^Tx^{(k)}/c^Tx^{(0)} \leq 2^{-q}\)
            }
        \end{algorithmic}
    \end{otherlanguage}
    \caption{\gr{Αλγόριθμος εσωτερικού σημείου του \tl{Karmarkar}}}
    \label{alg:ip_kar}
\end{figure}
Θα περιγράψουμε την ανανέωση της απεικόνισης \( \Psi \). Αρχικά, για να
υπολογίσουμε το πρώτο βήμα το κάνουμε από τη σχέση
\begin{equation*}
    x^{(1)} = x^{(0)} + \alpha d^{(0)},
\end{equation*}
με \( \alpha \) το μέγεθος τους βήματος και \( d^{(0)} \) η ανανέωση της
διεύθυνσης. Η παράγωγος της αντικειμενικής είναι \( c \). Επομένως, η διεύθυνση
της μέγιστης μείωσης είναι \( -c \). Όμως, στη γενική περίπτωση, δε μπορούμε να
ανανεώσουμε σε αυτή τη διεύθυνση διότι το σημείο \( x^{(1)} \) πρέπει να
βρίσκεται εντός του εφικτού συνόλου
\begin{equation*}
    \Omega \cap \Delta = \{ x\in\mathbb{R}^n: B_0x =
    \begin{pmatrix}0\\1\end{pmatrix}, x \geq 0 \},\quad
    \text{\gr{όπου }} B_0 = \begin{pmatrix}A \\ E^T\end{pmatrix}.
\end{equation*}
Όμως \( x^{(0)} \in \Omega \cap \Delta \), και για να ανήκει και το \( x^{(1)} =
x^{(0)} + \alpha d^{(0)} \) στο εφικτό σύνολο, πρέπει το διάνυσμα \( d^{(0)} \)
να ανήκει στο μηδενοχώρο του \( B_0\). Έτσι επιλέγουμε το \( d^{(0)} \) να
βρίσκεται στη διεύθυνση της ορθογώνιας προβολής του \( -c \) στο μηδενοχώρο του
\( B_0 \). Η προβολή αυτή περιγράφεται από τον πίνακα
\begin{equation*}
    P_0 = I_n - B_0^T(B_0B_0^T)^{-1}B_0.
\end{equation*}
Ο πίνακας \( B_0B_0^T \) είναι αντιστρέψιμος από την τρίτη υπόθεση.
Συγκεκριμένα, επιλέγουμε το \( d^{(0)}  = -r\hat{c}^{(0)} \), με
\begin{equation*}
    \hat{c}^{(0)} = \frac{P_0c}{\|P_0c\|},
\end{equation*}
και \( r = 1/ \sqrt{n(n - 1)} \). Έτσι το διάνυσμα \( d^{(0)} \) βρίσκεται στη
διεύθυνση της προβολής \( \hat{c}^{(0)} \) του \( c \) στο μηδενοχώρο του \( B_0
\) και το νέο σημείο \( x^{(1)} \) βρίσκεται στο εφικτό σύνολο \( \Omega \cap
\Delta \). Γενικεύοντας για κάθε επόμενο σημείο \( x^{(k)} \) ισχύει ότι
αναφέρθηκε μέχρι τώρα. Ένα σημείο που πρέπει να σημειώσουμε είναι ότι πρέπει να
μετατρέψουμε το σημείο σε κεντρικό του \tl{simplex}. Αυτό γίνεται θεωρώντας τον
πίνακα \( D_k = \mathtxt{diag}\left( x_1^{(k)}, \dots, x_n^{(k)} \right) \) και
την απεικόνιση \( U_k: \Delta \to \Delta \), με \( U_k(x) =
D_k^{-1}x/e^TD_k^{-1}x \).

Εφαρμόζοντας τους παραπάνω μετασχηματισμούς και ό,τι αναφέρθηκε για το πρώτο
βήμα, η διαδικασία για τον υπολογισμό της ανανέωσης \( x^{(k+1)} = \Psi(x^{(k)}) \)
μπορεί να συνοψιστεί στα παρακάτω βήματα.
\begin{enumerate}
    \item Υπολόγισε τους πίνακες
        \begin{equation*}
            D_k = \mathtxt{diag}\left( x_1^{(k)}, \dots, x_n^{(k)} \right), \quad
            B_k = \begin{pmatrix}AD_k \\ e^T\end{pmatrix}.
        \end{equation*}
    \item Υπολόγισε την ορθογώνια προβολή στο μηδενοχώρο του \(B_k\)
        \begin{equation*}
            P_k = I_n - B_k^T(B_kB_k^T)^{-1}B_k.
        \end{equation*}
    \item Υπολόγισε την κανονικοποιημένη ορθογώνια προβολή του \(c\) στο
        μηδενοχώρο του \(B_k\)
        \begin{equation*}
            \hat{c}^{(k)} = \frac{P_KD_kc}{\|P_kD_kc\|}.
        \end{equation*}
    \item Υπολόγισε το διάνυσμα διεύθυνσης
        \begin{equation*}
            d^{(k)} = -r \hat{c}^{(k)}, \quad \text{\gr{όπου }} r =
            \frac{1}{\sqrt{n(n - 1)}}.
        \end{equation*}
    \item Υπολόγισε \( \bar{x}^{(k+1)} \) από
        \begin{equation*}
            \bar{x}^{(k+1)} = a_0 + \alpha d^{(k)},
        \end{equation*}
        όπου \( \alpha \) είναι το προκαθορισμένο μέγεθος βήματος, \( \alpha \in
        (0, 1) \).
    \item Υπολόγισε \( x^{(k+1)} \) εφαρμόζοντας τον αντίστροφο μετασχηματισμό
        \( U_k^{-1} \)
        \begin{equation*}
            x^{(k+1)} = U_k^{-1}(\bar{x}^{(k+1)}) =
            \frac{D_k\bar{x}^{(k+1)}}{e^TD_k\bar{x}^{(k+1)}}.
        \end{equation*}
\end{enumerate}

\section{Αλγόριθμος \tl{path-following}}
Στο σημείο αυτό θα αναφέρουμε τον αλγόριθμο \tl{path-following}, γνωστός και ως
μέθοδος φράγματος (\tl{barrier method}) που είναι μέλος της οικογένειας των
\emph{μεθόδων εσωτερικού σημείου} για να λύσουμε προβλήματα κυρτής βελτιστοποίησης
που περιλαμβάνουν περιορισμούς ανισότητας και είναι της μορφής,
\begin{equation}\label{eq:ip_min}
    \begin{aligned}
        & \text{\tl{minimize}}
        & & f_0(x) \\
        & \text{\tl{subject to}}
        & & f_i(x) \leq 0, \quad i = 1,\dots,m, \\
        &&& Ax = b,
    \end{aligned}
\end{equation}
όπου \( f_0, \dots, f_m : \mathbb{R}^n \to \mathbb{R} \) είναι κυρτές και δύο
φορές συνεχώς παραγωγίσιμες, και \( A \in \mathbb{R}^{p \times n} \) με
\( \textbf{\tl{rank}} \ A = p < n \). Θεωρούμε ότι το πρόβλημα έχει λύση, δηλαδή
η βέλτιστη λύση \( x^* \) υπάρχει και θα συμβολίζουμε τη βέλτιστη τιμή \(
f_0(x^*) \) ως \( p^* \).

Επίσης, υποθέτουμε ότι το πρόβλημα είναι αυστηρώς εφικτό, δηλαδή υπάρχουν
\( \lambda^* \in \mathbb{R}^m, v^* \in \mathbb{R}^p \) τέτοια ώστε μαζί με το
\(x^*\) να ικανοποιούνται οι συνθήκες βέλτιστης λύσης \tl{Karush–Kuhn–Tucker}
(\tl{KKT})
\begin{equation}\label{eq:ip_kkt}
    \begin{split}
        Ax^* = b, \quad f_i(x^*) &\leq 0,\quad i = 1, \dots, m\\
        \lambda^* &\geq 0\\
        \nabla f_0(x^*) + \sum_{i=1}^m \lambda_i^* \nabla f_i(x^*) + A^Tv^* & = 0 \\
        \lambda_i^*f_i(x^*) & = 0,\quad i = 1, \dots, m.
    \end{split}
\end{equation}
Οι μέθοδοι εσωτερικού σημείου λύνουν το πρόβλημα \eqref{eq:ip_min} ή το
\eqref{eq:ip_kkt}, εφαρμόζοντας τη μέθοδο \tl{Newton} σε μία ακολουθία
προβλημάτων με περιορισμούς ισότητας, ή αντίστοιχα σε μία ακολουθία παραλλαγών
των συνθηκών \tl{KKT}. Για την ανάπτυξη της θεωρίας και τη διατύπωση του
αλγορίθμου θα βασιστούμε στο βιβλίο \cite{boyd2004convex}.

\subsection{Λογαριθμική συνάρτηση φράγματος και κεντρική διαδρομή}
Στόχος είναι να διατυπώσουμε το πρόβλημα με τους περιορισμούς ανισότητας
\eqref{eq:ip_min}, σε ισοδύναμο πρόβλημα με περιορισμούς ισότητας στο οποίο
μπορούμε να εφαρμόσουμε τη μέθοδο \tl{Newton}. Ενσωματώνοντας στην
αντικειμενική συνάρτηση  τους περιορισμούς ανισότητας προκύπτει
\begin{equation}\label{eq:ip_min_logbar}
    \begin{aligned}
        & \text{\tl{minimize}}
        & & f_0(x) + \sum_{i=1}^m I_{-}\left(f_i(x)\right)\\
        & \text{\tl{subject to}}
        & & Ax = b,
    \end{aligned}
\end{equation}
όπου \( I_{-}: \mathbb{R} \to \mathbb{R} \) είναι η συνάρτηση
\begin{equation*}
    I_{-}(u) =
    \begin{cases}
        0 \quad u \leq 0 \\
        \infty \quad u > 0.
    \end{cases}
\end{equation*}
Η βασική ιδέα της μεθόδου φράγματος είναι να προσεγγίσει τη συνάρτηση
\( I_{-} \) με τη συνάρτηση
\begin{equation*}
    \hat{I}_{-}(u) = (-1/t)\log{(-u)}, \quad \text{\tl{dom}}\ \hat{I}_{-} =
    -\mathbb{R}_{++},
\end{equation*}
όπου \( t > 0 \) είναι παράμετρος που θέτει την ακρίβεια της προσέγγισης. Όπως
η \( I_{-} \), η συνάρτηση \( \hat{I}_{-} \) είναι κυρτή και δεν μειώνεται και
κατά σύμβαση τείνει στο \( \infty \) όταν \( u > 0 \). Σε αντίθεση με την \(
I_{-} \), η \( \hat{I}_{-} \) είναι παραγωγίσιμη και κλειστή. Αντικαθιστώντας τη
\( \hat{I}_{-} \) στη θέση της \( I_{-} \) στην \eqref{eq:ip_min_logbar}
προκύπτει η προσέγγιση
\begin{equation}\label{eq:ip_min_logappr}
    \begin{aligned}
        & \text{\tl{minimize}}
        & & f_0(x) + \sum_{i=1}^m -(1/t)\log{(-f_i(x))} \\
        & \text{\tl{subject to}}
        & & Ax = b.
    \end{aligned}
\end{equation}
Η αντικειμενική στην παραπάνω σχέση είναι κυρτή, και αυξάνεται με το
\( u \) και διαφορίσιμη. Υποθέτοντας ότι υπάρχει συνθήκη για να είναι κλειστή,
τότε μπορούμε να λύσουμε με τη μέθοδο \tl{Newton}.

Η συνάρτηση
\begin{equation*}
    \phi(x) = - \sum_{i=1}^m \log{(-f_i(x))},
\end{equation*}
με \( \text{\tl{dom}}\ \phi = \{ x \in \mathbb{R}^n \mid f_i (x) < 0,\ i= 1,
\dots, m \} \), ονομάζεται λογαριθμική συνάρτηση φράγματος για το πρόβλημα
\eqref{eq:ip_min}.

\subsection{Κεντρική διαδρομή}
Έστω \( t > 0 \), ορίζουμε \( x^*(t) \) ως λύση της
\begin{equation*}
    \begin{aligned}
        & \text{\tl{minimize}}
        & & tf_0(x) + \phi(x) \\
        & \text{\tl{subject to}}
        & & Ax = b.
    \end{aligned}
\end{equation*}
Η \emph{κεντρική διαδρομή} (\tl{central path}) που σχετίζεται με το πρόβλημα
\eqref{eq:ip_min} ορίζεται ως το σύνολο των σημείων \( x^*(t), t > 0 \), τα
οποία ονομάζουμε \emph{κεντρικά σημεία} (\tl{central points}). Σημεία στην
κεντρική διαδρομή χαρακτηρίζονται από τις ακόλουθες αναγκαίες και ικανές
συνθήκες: \( x^*(t) \) είναι αυστηρώς εφικτό, δηλαδή ισχύει
\begin{equation*}
    Ax^*(t) = b, \quad f_i(x^*(t)) < 0, \quad i = 1,\dots, m,
\end{equation*}
και υπάρχει διάνυσμα \( \hat{v} \in \mathbb{R}^p \) τέτοιο ώστε
να ισχύει
\begin{equation*}
    0 = t\nabla f_0 (x^*(t)) + \nabla \phi (x^*(t)) + A^T \hat{v}
\end{equation*}
ή ισοδύναμα με αντικατάσταση της κλίσης \( \nabla \phi (x^*(t)) \)
\begin{equation}\label{eq:ip_cpc}
    0 = t\nabla f_0 (x^*(t)) + \sum_{i = 1}^m \dfrac{1}{-f_i(x^*(t))} \nabla f_i
    (x^*(t)) + A^T \hat{v}.
\end{equation}
\textbf{Δυϊκά σημεία από την κεντρική διαδρομή}. Μία σημαντική ιδιότητα της
κεντρικής διαδρομής είναι ότι κάθε κεντρικό σημείο
παράγει ένα δυϊκό εφικτό σημείο, και έτσι ένα κάτω όριο στην βέλτιστη τιμή
\( p^* \). Πιο συγκεκριμένα αν ορίσουμε
\begin{equation}\label{eq:ip_dual_feas}
    \lambda_i^*(t) = - \dfrac{1}{t f_i(x^*(t))},\quad i = 1, \dots, m,
    \quad v^*(t) = \hat{v}/t,
\end{equation}
τότε το ζεύγος \( \lambda^*(t), v^*(t) \) είναι δυϊκό εφικτό. Αρχικά,
\(\lambda^*(t) > 0 \) επειδή \(f_i(x^*(t)) < 0\). Αντικαθιστώντας στην
σχέση \eqref{eq:ip_cpc} την παραπάνω προκύπτει
\begin{equation*}
    t\nabla f_0 (x^*(t)) + \sum_{i = 1}^m \lambda_i^*(t) \nabla f_i
    (x^*(t)) + A^T \hat{v}(t) = 0,
\end{equation*}
και βλέπουμε ότι το \( x^*(t) \) ελαχιστοποιεί τη Λαγκρανζιανή
\begin{equation*}
    L(x, \lambda, v) = f_0(x) + \sum_{i = 1}^m \lambda_i \nabla f_i
    (x) + v^T(Ax - b),
\end{equation*}
για \( \lambda = \lambda^*(t) \) και \( v = v^*(t) \), που σημαίνει ότι τα
\( \lambda^*(t), v^*(t) \) είναι δυϊκό εφικτό ζεύγος. Συνεπώς, η δυϊκή συνάρτηση
είναι πεπερασμένη
\begin{align*}
    g(\lambda^*(t), v^*(t)) &=  f_0(x^*(t)) + \sum_{i = 1}^m \lambda_i^*(t) \nabla f_i
    (x^*(t)) + v^*(t)^T(Ax^*(t) - b) \\
    &= f_0(x^*(t)) - m/t,
\end{align*}
και συνεπώς το δυϊκό κενό μεταξύ του \( x^*(t) \) και του δυϊκού ζεύγους
\( \lambda^*(t), v^*(t) \) είναι απλά \( m/t \). Ως επακόλουθο αυτού έχουμε
\begin{equation*}
    f_0(x^*(t)) - p^* \leq m/t,
\end{equation*}
που επιβεβαιώνει τη διαισθητική ιδέα ότι το \( x^*(t) \) συγκλίνει σε βέλτιστο
σημείο καθώς \( t \to \infty \).

\textbf{Ερμηνεία μέσω των συνθηκών \tl{KKT}}. Μπορούμε να ερμηνεύσουμε τις
συνθήκες κεντρικής διαδρομής \eqref{eq:ip_cpc} ως ένα συνεχή μετασχηματισμό των
συνθηκών \tl{KKT} \eqref{eq:ip_kkt}. Ένα σημείο \( x \) ισούται με το \( x^*(t)
\) αν και μόνο αν υπάρχουν  \( \lambda, v \) τέτοια ώστε
\begin{equation*}
    \begin{split}
        Ax = b, \quad f_i(x^*) &\leq 0,\quad i = 1, \dots, m\\
        \lambda &\geq 0\\
        \nabla f_0(x) + \sum_{i=1}^m \lambda_i \nabla f_i(x) + A^Tv & = 0 \\
        -\lambda_if_i(x) & = 1/t,\quad i = 1, \dots, m.
    \end{split}
\end{equation*}
Η μόνη διαφορά των παραπάνω και των συνθηκών \eqref{eq:ip_kkt} είναι ότι η
συμπληρωματική συνθήκη \( - \lambda_i f_i(x) = 0 \) αντικαταστήθηκε από τη
συνθήκη \( - \lambda_i f_i(x) = 1/t \).

\textbf{Ερμηνεία μέσω δυνάμεων πεδίου}. Συσχετίζουμε με κάθε περιορισμό τη
δύναμη
\begin{equation*}
    F_i(x) = - \nabla (- \log{(-f_i(x))}) = \dfrac{1}{f_i(x)} \nabla f_i(x)
\end{equation*}
που επιδρά στο \tl{``}σωματίδιο\tl{''} στη θέση \( x \). Η συνολική δύναμη που
δημιουργείται από τους περιορισμούς είναι η λογαριθμική συνάρτηση φράγματος
\(\phi \). Καθώς το σωματίδιο κινείται προς το όριο του εφικτού συνόλου,
απωθείται έντονα από τις δυνάμεις που δημιουργούνται από τους περιορισμούς.

Έστω τώρα μία άλλη δύναμη που επιδρά στο σωματίδιο
\begin{equation*}
    F_0(x) = - t\nabla f_0(x),
\end{equation*}
στο σωματίδιο στη θέση \( x \). Αυτή η αντικειμενική δύναμη πεδίου επιδρά
έλκοντας το σωματίδιο στην αντίθετη κατεύθυνση της κλίσης. Η παράμετρος
\( t \) κλιμακώνει την αντικειμενική σχετικά με τους περιορισμούς δύναμης.

Το κεντρικό σημείο \( x^*(t) \) είναι το σημείο που οι περιορισμοί δύναμης
ισορροπούν με τη δύναμη της αντικειμενικής στο σωματίδιο. Καθώς η παράμετρος
\( t \)  μεγαλώνει, το σωματίδιο έλκεται εντονότερα προς το βέλτιστο σημείο,
αλλά πάντα μένει εντός του εφικτού συνόλου λόγω της επίδρασης των περιορισμών.

\subsection{Διατύπωση του αλγορίθμου \tl{path-following}}
Η μέθοδος αυτή βασίζεται στην επίλυση μίας ακολουθίας χωρίς περιορισμούς (ή με
γραμμικούς περιορισμούς) προβλημάτων ελαχιστοποίησης, χρησιμοποιώντας το
τελευταίο σημείο που υπολογίστηκε ως αρχική λύση για το επόμενο πρόβλημα
ελαχιστοποίησης χωρίς περιορισμούς. Με άλλα λόγια, υπολογίζουμε το
\( x^*(t) \) για μία ακολουθία με αυξανόμενη την τιμή του \( t \), μέχρι
\(  t \geq m/\epsilon \), που μας εξασφαλίζει ότι θα έχουμε ένα βέλτιστο
υποπρόβλημα του αρχικού προβλήματος με απόκλιση \( \epsilon \).  Η μέθοδος
αρχικά προτάθηκε από τον \tl{Fiacco} και \tl{McCormick} τη δεκαετία του
\(1960\). Σήμερα η μέθοδος αυτή είναι γνωστή ως \emph{μέθοδος φράγματος}
(\tl{barrier method}) ή \emph{\tl{path-following} μέθοδος} και εφαρμόζεται
ευρέως για την επίλυση προβλημάτων. Ο αλγόριθμος της
μεθόδου παρουσιάζεται στο \ref{alg:ip_bm}.
\begin{figure}[h]
    \begin{otherlanguage}{english}
        \begin{algorithmic}
            \REQUIRE \text{\gr{αυστηρώς εφικτό σημείο }}$x,
            t:=t^{(0)}>0,\mu>1,$\text{\gr{ ανοχή }}$\epsilon>0.$
            \REPEAT
            \STATE \text{\gr{1. Κεντρικό βήμα. }}
            \text{\gr{Υπολόγισε }}\(x^*(t)\)\text{\gr{ ελαχιστοποιώντας }}
            \( tf_0 + \phi \)
            \STATE \text{\gr{ που υπόκειται }} \(Ax = b \)\text{\gr{,
            ξεκινώντας από το }}\(x.\)
            \STATE \text{\gr{2. Ανανέωσε. }}\(x := x^*(t).\)
            \UNTIL{\text{\gr{3. Κριτήριο τερματισμού }} \( m/t < \epsilon \)}
            \STATE \text{\gr{4. Αύξησε. }}\(t := \mu t.\)
        \end{algorithmic}
    \end{otherlanguage}
    \caption{\gr{Αλγόριθμος \tl{path-following}}}
    \label{alg:ip_bm}
\end{figure}

Σε κάθε επανάληψη (εκτός της πρώτης) υπολογίζουμε το κεντρικό σημείο
\( x^*(t) \) ξεκινώντας από το προηγούμενο κεντρικό σημείο που υπολογίστηκε, και
στη συνέχεια αυξάνουμε το \( t \) κατά συντελεστή \( \mu > 1 \). Ο αλγόριθμος
μπορεί επίσης να επιστρέψει το δυϊκό σημείο \( \lambda = \lambda^*(t), v =
v^*(t) \).

Ονομάζουμε κάθε εκτέλεση του βήματος \( 1 \), κεντρικό βήμα ή εξωτερική επανάληψη,
καθώς τότε υπολογίζουμε κεντρικά σημεία, και του πρώτου κεντρικού βήματος ως
αρχικό κεντρικό βήμα.  Μπορούμε να χρησιμοποιήσουμε διάφορες μεθόδους για την
επίλυση του προβλήματος ελαχιστοποίησης με γραμμικού περιορισμούς που προκύπτει
στην επανάληψη του κεντρικού βήματος, όπως για παράδειγμα τη μέθοδο
\tl{Newton} και αναφερόμαστε στην επαναλήψεις κατά τη μέθοδο \tl{Newton}
ως εσωτερικές επαναλήψεις. Σε κάθε εσωτερική επανάληψη έχουμε ένα βασικό
εφικτό σημείο, αλλά δυϊκό εφικτό σημείο έχουμε στο τέλος του κεντρικού βήματος.

Ο υπολογισμός του \( x^*(t) \) με μεγάλη ακρίβεια δεν είναι απαραίτητο καθώς η
κεντρική διαδρομή θα συγκλίνει σε βέλτιστο σημείο ακόμα και όταν το
\( x^*(t) \) δεν έχει υπολογισθεί με μεγάλη ακρίβεια. Σε αυτήν την περίπτωση
όμως τα δυϊκά σημεία \( \lambda^*(t), v^*(t) \) δεν είναι δυϊκά εφικτά. Αυτό
μπορεί να διορθωθεί προσθέτοντας ένα διορθωτικό όρο στις σχέσεις
\eqref{eq:ip_dual_feas} που υπολογίζονται. Από την άλλη, το κόστος υπολογισμού
ελαχιστοποίησης με μεγάλη ακρίβεια της \( tf_0 + \phi \) είναι οριακά μεγαλύτερο
από το κόστος υπολογισμού του ελάχιστου της συνάρτησης με μία ικανοποιητική
ακρίβεια, μερικά \tl{Newton} βήματα μακριά.

Η επιλογή της παραμέτρου \( \mu \) επηρεάζει τις εσωτερικές και εξωτερικές
επαναλήψεις του αλγορίθμου. Αν το \( \mu \) είναι μικρό τότε σε κάθε εξωτερική
επανάληψη το \(t\) αυξάνει κατά ένα μικρό ποσοστό. Ως αποτέλεσμα αυτού, το
αρχικό σημείο για κάθε φορά που εφαρμόζουμε τη μέθοδο \tl{Newton} είναι πολύ
καλό και ο αριθμός των επαναλήψεων που απαιτείται για να συγκλίνει η μέθοδος
\tl{Newton} είναι μικρός. Έτσι για μικρό \( \mu \) αναμένουμε μικρό αριθμό
βημάτων \tl{Newton} στις εξωτερικές επαναλήψεις, αλλά μεγάλο αριθμό εξωτερικών
επαναλήψεων καθώς κάθε εξωτερική επανάληψη μειώνει την απόκλιση της απόστασης
του σημείου από το βέλτιστο κατά ένα μικρό ποσοστό. Στην περίπτωση αυτή πολλές
φορές ο αλγόριθμος συναντάται με την ονομασία \tl{short-step path-following} ή
\tl{SPF}.

Αντίθετα, όταν το \( \mu \) είναι μεγάλο έχουμε την ακριβώς αντίθετη
συμπεριφορά. Μετά από κάθε εξωτερική επανάληψη το \(t\) αυξάνεται κατά μεγάλο
ποσοστό, έτσι η συγκεκριμένη επανάληψη πιθανόν δεν είναι αρκετά καλή προσέγγιση
της επόμενης επανάληψης. Έτσι αναμένουμε πολλές εσωτερικές επαναλήψεις. Αυτή η
επιθετική επιλογή της παραμέτρου \( t\) οδηγεί σε λιγότερες εξωτερικές
επαναλήψεις, αλλά σε περισσότερες εσωτερικές. Στην περίπτωση αυτή πολλές
φορές ο αλγόριθμος συναντάται με την ονομασία \tl{long-step path-following} ή
\tl{LPF}.

Μία άλλη επιλογή που έχουμε να κάνουμε είναι η αρχική τιμή του \(t\). Αν το
\(t^{(0)}\) είναι πολύ μεγάλο, η πρώτη εξωτερική επανάληψη θα χρειαστεί πολλές
επαναλήψεις. Αν το \(t^{(0)}\) είναι πολύ μικρό, ο αλγόριθμος θα χρειαστεί
πολλές εξωτερικές επαναλήψεις και πιθανόν πολλές εσωτερικές στο πρώτο κεντρικό
βήμα.

Για περαιτέρω ανάλυση σχετικά με τον αλγόριθμο \tl{path-following}
και την ανάλυση σύγκλισης, την πολυπλοκότητα κτλ καθώς για διάφορες παραλλαγές
του αλγορίθμου όπως ο αλγόριθμος πρόβλεψης-διόρθωσης
(\tl{predictor-corrector}), ο ενδιαφερόμενος αναγνώστης παραπέμπεται στη
βιβλιογραφία, ενδεικτικά αναφέρονται τα βιβλία
\cite{boyd2004convex}, \cite{renegar2001mathematical},
\cite{nesterov1994interior}, \cite{wright1997primal}.

\section{\tl{Primal-dual} μέθοδοι εσωτερικού σημείου}
Θα αναφερθούμε επιγραμματικά στη μέθοδο \tl{primal-dual} εσωτερικού σημείου. Η
μέθοδος αυτή έχει αρκετά κοινά με τη μέθοδο \tl{path-following} αλλά με κάποιες
διαφορές. Πρώτη διαφορά είναι ότι υπάρχει μία μόνο επανάληψη, δηλαδή δεν υπάρχει
διαφορά μεταξύ της εσωτερικής και της εσωτερικής επανάληψης και σε κάθε
επανάληψη ανανεώνονται οι βασικές και οι δυϊκές μεταβλητές. Δεύτερον, η
διεύθυνση εύρεσης της λύσης, στη μέθοδο \tl{primal-dual} λαμβάνεται από τη
μέθοδο \tl{Newton} που εφαρμόζεται σε παραλλαγή των συνθηκών \tl{KKT}. Η λογική
εύρεσης της διεύθυνσης είναι παρόμοια με αυτή της μεθόδου \tl{path-following}
αλά όχι η ίδια. Τέλος, στη μέθοδο \tl{primal-dual}, οι βασικές και δυϊκές
μεταβλητές κατά τη διάρκεια των επαναλήψεων δεν είναι απαραίτητα εφικτές.

Η \tl{primal-dual} μέθοδος είναι πολλές φορές περισσότερο αποδοτική από τη
μέθοδο \tl{path-following}, ειδικά όταν απαιτείται μεγάλη ακρίβεια. Για πολλές
κατηγορίες προβλημάτων όπως προβλήματα, γραμμικού, τετραγωνικού, ημι-ορισμένου
προγραμματισμού κτλ η μέθοδος \tl{primal-dual} είναι αρκετά αποδοτικότερη από
τη μέθοδο \tl{path-following}. Για γενικά προβλήματα μη-γραμμικού
προγραμματισμού η καθιέρωση της μεθόδου είναι αντικείμενο μελέτης αλλά με
θετικά σημάδια.

\subsection{\tl{Primal-dual} διεύθυνση εύρεσης}
Ξεκινάμε με τροποποίηση των συνθηκών \tl{KKT} εκφραζόμενες ως
\( r_t(x, \lambda, v) = 0 \) και
\begin{equation*}
    r_t(x, \lambda, v) = \begin{pmatrix}
        \nabla f_0(x) + Df(x)^T\lambda + A^Tv \\
        -\mathtxt{diag}(\lambda)f(x) - (1/t)\vc{1} \\
        Ax - b
    \end{pmatrix},
\end{equation*}
με \( t > 0\) και \( f: \mathbb{R}^n \to \mathbb{R}^m \). Συγκεκριμένα, \(x\)
είναι η βασική μεταβλητή και \(\lambda, v\) είναι οι δυϊκές. Το πρώτο μπλοκ
γραμμών στην παραπάνω λέγεται δυϊκό υπόλοιπο, \(r_{dual} \), το τελευταίο βασικό
υπόλοιπο, \(r_{pri} \) και το μεσαίο υπόλοιπο κεντρικότητας \(r_{cent} \).
Αν συμβολίσουμε \( y = (x, \lambda, v) \) τότε το επόμενο βήμα \tl{Newton}
είναι \( r_t(y + \Delta y) \approx r_t(y) + Dr_t(y)\Delta y = 0 \),
και άρα το νέο σημείο είναι \( \Delta y = -Dr_t(y)^{-1}r_t(y) \). Δηλαδή,
για να υπολογίσουμε το νέο σημείο, \tl{primal-dual} διεύθυνση λύσης \(\Delta
y_{pd} \), πρέπει να λύσουμε το σύστημα
\begin{equation*}
    \begin{pmatrix}
        \nabla^2 f_0(x) + \sum \lambda_i \nabla^2 f_i(x) & Df(x)^T & A^T \\
        -\mathtxt{diag}(\lambda)Df(x) & - \mathtxt{diag}(f(x)) & 0 \\
        A & 0 & 0
    \end{pmatrix}
    \begin{pmatrix}
        \Delta x\\
        \Delta \lambda\\
        \Delta v
    \end{pmatrix} = -
    \begin{pmatrix}
        r_{dual}\\
        r_{cent}\\
        r_{pri}
    \end{pmatrix}.
\end{equation*}

\subsection{Διατύπωση του αλγορίθμου \tl{primal-dual}}
Στο σημείο αυτό θα παρουσιάσουμε τη μέθοδο σε μορφή αλγορίθμου και θα
σχολιάσουμε κάποια στοιχεία αυτής.
\begin{figure}[h]
    \begin{otherlanguage}{english}
        \begin{algorithmic}
            \REQUIRE \(x\)\text{\gr{ που ικανοποιεί }}
            \(f_1(x) <0, \dots, f_m(x) < 0, \lambda > 0, \mu > 1,
            \epsilon_{feas} > 0, \epsilon > 0.\)
            \REPEAT
            \STATE \text{\gr{1. Υπολόγισε \(t\). }}
            \text{\gr{Όρισε }}\(t := \mu m / \hat{\eta}.\)
            \STATE \text{\gr{2. Υπολόγισε }\tl{primal-dual }\gr{διεύθυνση λύσης.
            }}\(\Delta y_{pd}.\)
            \STATE \text{\tl{3. Line search }\gr{και ανανέωση.}}
            \STATE \(\qquad\)\text{\gr{Υπολόγισε μήκος βήματος }}
            \( s > 0 \)\text{\gr{ και όρισε }} \(y := y + s \Delta y_{pd}.\)
            \UNTIL{ \( \|r_{pri}\|_2 \leq \epsilon_{feas},
                \|r_{dual}\|_2 \leq \epsilon_{feas}\)\text{\gr{ και }}
            \( \hat{\eta} \leq \epsilon \)}
        \end{algorithmic}
    \end{otherlanguage}
    \caption{\gr{Αλγόριθμος \tl{primal-dual} εσωτερικού σημείου}}
    \label{alg:ip_pd}
\end{figure}
Στο πρώτο βήμα του αλγορίθμου, θέτουμε την παράμετρο \(t = \mu m /\hat{\eta}\),
που σχετίζεται με το αντίστοιχο δυϊκό κενό \(\hat{\eta}\). Που ορίζεται για το
\(x\) που ικανοποιεί \( f(x) < 0 \) και \( \lambda \geq 0 \) ως \( \hat{\eta}  =
f(x)^T\lambda \) και αν \( r_{pri} = 0 \) και \( r_{dual} = 0 \) τότε θα ήταν
ίσο με το δυϊκό κενό δηλαδή θα εξέφραζε την απόκλιση της βασικής από τις δυϊκές
μεταβλητές, όπως το είδαμε στην προηγούμενη ενότητα. Αν τα \( x, \lambda, v \)
ακολουθούσαν κεντρική διαδρομή, όπως στον αλγόριθμο \tl{path-following},
τότε θα αυξάναμε την παράμετρο \(t\) επί την ποσότητα \(\mu\). Ο αλγόριθμος
\ref{alg:ip_pd} τερματίζει όταν βασική μεταβλητή \(x\) και οι δυϊκές \(\lambda,
v \) είναι εφικτές, με απόκλιση όσο η ανοχή \( \epsilon_{feas} \), και όταν το
κενό \( \hat{\eta} \) είναι μικρότερο της ανοχής \( \epsilon \). Επειδή η
μέθοδος αυτή είναι γρήγορη γραμμική σύγκλιση, είναι συνηθισμένο να επιλέγουμε
μικρές ανοχές.

Για να υπολογίσουμε το μήκος βήματος \( s \), αρχικά βρίσκουμε το μέγιστο δυνατό
που δίνει για το νέο σημείο \( \lambda^+ \geq 0 \),
\begin{align*}
    s^{max} &= \mathtxt{sup}\{s \in [0,1] : \lambda + s \Delta \lambda \geq 0 \}
    \\
    &= \mathtxt{min}\{1, \mathtxt{min}\{ -\lambda_i/\Delta \lambda_i: \Delta
        \lambda_i < 0 \}.
\end{align*}
Εφόσον βρούμε το μέγιστο \( s^{max} \) βρίσκουμε το μήκος βήματος \( s = \beta
s^{max} \) με \( \beta \in (0, 1) \) μέχρι να ικανοποιείται η ανισότητα
\begin{equation*}
    \| r_t(x^+, \lambda^+, v^+) \|_2 \leq (1 - \alpha s) \|r_t(x, \lambda, v) \|_2,
\end{equation*}
με τυπικές τιμές για τις παραμέτρους \( (\alpha, \beta) \) να είναι στο εύρος \(
0.01\) με \(0.1\) για τη πρώτη και \( 0.3\) με \(0.8\) για τη δεύτερη.
